{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "source": [
    "# Topic extraction from the GEPRiS dataset and creation of an user-centric visualisation\n",
    "Author: Tim Korjakow        \n",
    "Summer term 2018      \n",
    "Freie Universit√§t Berlin     \n",
    "Fachgebiet Human-Centered Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "source": [
    "![Process graph](nlpflowchart.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f19ed59b3cf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msilhouette_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy.stats import entropy\n",
    "import bz2\n",
    "import csv\n",
    "from bokeh.palettes import d3\n",
    "\n",
    "from Preprocessing.preprocessing import Preprocessing\n",
    "from Embedding.embedding import Embedding\n",
    "from Topicextraction.topicextraction import TopicExtraction\n",
    "from Clustering.clustering import Clustering\n",
    "from Planereduction.planereduction import PlaneReduction\n",
    "from Linearization.linearization import mapToSpaceSampling, computeClusterTopography\n",
    "from Debug.debug import Debug\n",
    "from sklearn.manifold import MDS\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# interactivity\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider, Dropdown, FloatSlider, fixed\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Javascript, HTML\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with bz2.open('../../../assets/data/train.csv.bz2', mode='rt') as f:\n",
    "#    csvreader = csv.reader(f)\n",
    "#    traindata = Preprocessing().fit_transform((row[1] for row in csvreader))\n",
    "#    f.seek(0)\n",
    "#    doc2author = {i:row[3:] for i, row in enumerate(csvreader)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(list(doc2author.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "#\t'Doc2Vec': Embedding(method='Doc2Vec', model_path='../../../assets/models/doc2vec/doc2vec.joblib'),\n",
    "#\t'TfIdf': Embedding(method='TfIdf', dict_path='../../../assets/models/dict/dict.joblib', model_path='../../../assets/models/tfidf/tfidf.joblib'),\n",
    "\t'ATM': Embedding(method='ATM', dict_path='../models/dict/dict.joblib', model_path='../models/atm/atm.joblib')\n",
    "}\n",
    "\n",
    "print('Finished loading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"ATM\"].selector.transform(1).shape\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in models[\"ATM\"].selector.model.show_topics(num_topics=10):\n",
    "    #print('Label: ' + topic_labels[topic[0]])\n",
    "    words = ''\n",
    "    for word, prob in models[\"ATM\"].selector.model.show_topic(topic[0]):\n",
    "        words += word + ' '\n",
    "    print('Words: ' + words)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{subject:len(docs) for subject, docs in models[\"ATM\"].selector.model.author2doc.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "hellinger = lambda x,y : np.linalg.norm(np.sqrt(x)-np.sqrt(y))/np.sqrt(2)\n",
    "pipe = Pipeline([('Embedding', models['ATM']),\n",
    "                 ('EmbeddingData', Debug()),\n",
    "                 ('PlaneReduction', PlaneReduction(2, method='TSNE', perplexity=6, metric=jensenshannon))], verbose=True)\n",
    "\n",
    "tfs_plane, labels = pipe.fit_transform(np.ones((10,10)))\n",
    "\n",
    "#tfs_reduced = pipe.named_steps.TopicExtractionData.data\n",
    "#print(tfs_reduced.shape)\n",
    "\n",
    "# compute linearization\n",
    "tfs_mapped = mapToSpaceSampling(tfs_plane)\n",
    "\n",
    "# compute cluster topography\n",
    "uncertainty = entropy(np.array(pipe.named_steps.EmbeddingData.data[0]).T + 0.000001)\n",
    "\n",
    "print(len(models[\"ATM\"].selector.model.doc2author.items()))\n",
    "interpolated_topography = computeClusterTopography(tfs_mapped, uncertainty, 600, 600, 'cubic')\n",
    "dump = {\n",
    "            'project_data': [{'mappoint':mappoint, 'embpoint':embpoint, 'cluster':cluster, 'entropy': entropy, 'title':title, 'doc_count':doc_count} for mappoint, embpoint, cluster, entropy, title, doc_count in zip(\n",
    "                tfs_mapped.tolist(),\n",
    "                tfs_plane.tolist(),\n",
    "                LabelEncoder().fit_transform([x[2] for x in models[\"ATM\"].selector.model.doc2author.values()]).tolist(),\n",
    "                uncertainty.tolist(),\n",
    "                list(models[\"ATM\"].selector.model.id2author.values()),\n",
    "                [len(models[\"ATM\"].selector.model.author2doc[author]) for author in models[\"ATM\"].selector.model.id2author.values()]\n",
    "            )],\n",
    "            'cluster_data': {\n",
    "                'cluster_colour': d3['Category20'][4]\n",
    "            },\n",
    "            'cluster_topography': np.flip(interpolated_topography.T, axis=0).flatten().tolist(),\n",
    "            'topography_width': 600,\n",
    "            'topography_height': 600\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_scatter(data, width=600, height=600, viz='linearized'):\n",
    "    display(Javascript(\"\"\"\n",
    "        (function(element){\n",
    "            require(['scatter'], function(scatter) {\n",
    "                scatter(element.get(0), %s, %d, %d, %s);\n",
    "            });\n",
    "        })(element);\n",
    "    \"\"\" % (json.dumps(data), width, height, json.dumps(viz))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "outputs": [],
   "source": [
    "def visualize(dump=None):\n",
    "    # viz dimensions\n",
    "    width = 600\n",
    "    height = 600\n",
    "\n",
    "    display(HTML(filename=\"scatter.css.html\"))\n",
    "    display(Javascript(\"require.config({paths: {d3: 'https://d3js.org/d3.v5.min'}});\"))\n",
    "    display(Javascript(filename=\"scatter.js\"))\n",
    "    draw_scatter(dump, width, height)\n",
    "    with open('./dump.json', 'w+') as f:\n",
    "        json.dump(dump, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "scrolled": false
    },
    "remote_metadata": {
     "scrolled": false,
     "tags": [
      "remove_cell"
     ]
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w = interactive(visualize, dump=fixed(dump))\n",
    "display(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
